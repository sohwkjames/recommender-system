{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a recommender system from scratch\n",
    "\n",
    "Part 2 of 2\n",
    "\n",
    "*Written by: James Soh*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(0)\n",
    "plt.style.use('ggplot')\n",
    "np.set_printoptions(suppress=True)\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('./ml-latest-small/movies.csv', names=['MovieID', 'Title', 'Genres'], header=0)\n",
    "ratings_df = pd.read_csv('./ml-latest-small/ratings.csv', names=['UserID', 'MovieID', 'Rating', 'Timestamp'], header=0)\n",
    "tags_df = pd.read_csv('./ml-latest-small/tags.csv', names=['UserID', 'MovieID', 'tag', 'Timestamp'], header=0)\n",
    "links_df = pd.read_csv('./ml-latest-small/links.csv', names=['MovieID', 'imdbId', 'tmbdId'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links_df = pd.read_csv('./ml-latest-small/links.csv', names=['MovieID', 'imdbId', 'tmbdId'], header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split and utilizing implicit data (timestamp)\n",
    "\n",
    "I chose a train ratio of 0.7 so as not to overfit.\n",
    "\n",
    "Each user's ratings has a timestamp attached to it. I will set 30% of each user's latest ratings as the test set. Because we want to make predictions for a user's future preferences, fitting our model for the user's latest ratings will give the best predictions for a user's future preferences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(data, train_ratio):\n",
    "    '''Creates a train/test split from a pandas DataFrame that contains rating data. The dataframe should have\n",
    "    columns = ['UserID', 'MovieID', 'Rating', 'Timestamp']. For each user, items are sorted by timestamp before sending to\n",
    "    test set. Hence test set will contain users latest ratings.\n",
    "    \n",
    "    Args:\n",
    "        data: Ratings dataframe\n",
    "        train_ratio: float between 0 and 1\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    train = pd.DataFrame(columns=data.columns)\n",
    "    test = pd.DataFrame(columns=data.columns)\n",
    "    users = list(set(data['UserID']))\n",
    "    dummy_movieid = list(ratings_df.MovieID.unique()) #To ensure our matrix later contains all MovieID.\n",
    "    dummy_movieid = pd.DataFrame({'UserID':999, 'MovieID':dummy_movieid, 'Rating':0, 'Timestamp':0})\n",
    "    for u in users:\n",
    "        temp = data[data['UserID'] == u]\n",
    "        n = len(temp)\n",
    "        test_size = int(train_ratio*n)\n",
    "        temp = temp.sort_values('Timestamp', ascending=False).reset_index(drop=True)\n",
    "        dummy_train = temp.iloc[:test_size]\n",
    "        dummy_test = temp.iloc[test_size:]\n",
    "        train = pd.concat([train, dummy_train])\n",
    "        test = pd.concat([test, dummy_test])\n",
    "    train = train.append(dummy_movieid)\n",
    "    test = test.append(dummy_movieid)\n",
    "\n",
    "    \n",
    "    return train, test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings_df, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58904, 4)\n",
      "(59232, 4)\n"
     ]
    }
   ],
   "source": [
    "print train.shape\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorizing the matrix and minimizing error with gradient descent.\n",
    "\n",
    "Given set of U users, set of D items. R is the matrix of size U x D. We want to discover K latent features. \n",
    "\n",
    "Our task is to find 2 smaller matrices P and Q that best approximates R.\n",
    "\n",
    "P represents user feature vectors, and Q represents item feature vectors. (Or, how much a user likes a certain concept, and how much a certain concept is represented in a movie.)\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{R} \\approx \\mathbf{P} \\times \\mathbf{Q}^T = \\hat{\\mathbf{R}}\n",
    "\\end{equation*}  \n",
    "\n",
    "To get the prediction of an item in the matrix, calculate dot product of the 2 corrosponding vectors.\n",
    "\n",
    "\n",
    "\\begin{equation*} \n",
    "\\hat{r}_{ij} = p_i^T q_j = \\sum_{k=1}^k{p_{ik}q_{kj}}\n",
    "\\end{equation*}\n",
    "\n",
    "Now, initialize P and Q with random values, calculate how different the product is to matrix R, and try to reduce the difference iteratively.\n",
    "\n",
    "\n",
    "\\begin{equation*} \n",
    "e_{ij}^2 = (r_{ij} - \\hat{r}_{ij})^2 = (r_{ij} - \\sum_{k=1}^K{p_{ik}q_{kj}})^2\n",
    "\\end{equation*}\n",
    "\n",
    "Need to find the gradient to know which direction to modify P(i,k) and Q(k,j)\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial}{\\partial p_{ik}}e_{ij}^2 = -2(r_{ij} - \\hat{r}_{ij})(q_{kj}) = -2 e_{ij} q_{kj}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial}{\\partial q_{ik}}e_{ij}^2 = -2(r_{ij} - \\hat{r}_{ij})(p_{ik}) = -2 e_{ij} p_{ik}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "Now, we can form our update rules. Also attach a learning rate.\n",
    "\\begin{equation*}\n",
    "p'_{ik} = p_{ik} + \\alpha \\frac{\\partial}{\\partial p_{ik}}e_{ij}^2 = p_{ik} + 2\\alpha e_{ij} q_{kj} \n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "q'_{kj} = q_{kj} + \\alpha \\frac{\\partial}{\\partial q_{kj}}e_{ij}^2 = q_{kj} + 2\\alpha e_{ij} p_{ik} \n",
    "\\end{equation*}\n",
    "\n",
    "I am only reducing the errors of known item:value pairs. Our latent vectors will be discovered, and then we can form predictions on unkown items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def initialize_random_matrices(ratings, K):\n",
    "        '''\n",
    "        Returns 2 matrices of size N,K and M,K that contains random floats from 0 to 1. \n",
    "\n",
    "        Args:\n",
    "            ratings: N by M matrix containing ratings. Rows are users, columns are products.\n",
    "            K: Number of latent factors to discover\n",
    "            \n",
    "        '''\n",
    "        R = np.array(ratings)\n",
    "        N = len(R) \n",
    "        M = len(R[0])  \n",
    "        P = np.random.random((N,K))\n",
    "        Q = np.random.random((M,K)) #Note: We will transpose this matrix later.\n",
    "        return P, Q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick demonstration of the GD in action. \n",
    "\n",
    "this demonstration I've set the learning rate to be quite high (0.01) with a small amount of steps (5), and to print the product of the 2 smaller matrixes. Let's observe how the product of the component matrices converge towards the original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_factorization_test(R, P, Q, K, steps=1000, alpha=0.0002, beta=0.02):\n",
    "    Q = Q.T\n",
    "    for step in xrange(steps):\n",
    "        for i in xrange(len(R)): # iterate over rows (or users)\n",
    "            for j in xrange(len(R[i])): # for each user, iterate all items. 30 times.\n",
    "                #Hence, iterate over entire row of matrix R, before moving on to next row.\n",
    "                if R[i][j] > 0: # If a given element in a matrix is > 0, aka user has actually rated an item\n",
    "                    # eij is the error for a given element in matrix R\n",
    "                    eij = R[i][j] - np.dot(P[i,:],Q[:,j]) \n",
    "                    # Iterate over the user:feature matrix.\n",
    "                    for k in xrange(K): # K is number of latent features. \n",
    "                        # Updating each indivudual feature of the matrix P and matrix Q. \n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eR = np.dot(P,Q)\n",
    "        e = 0\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])): #for elements in the original matrix:\n",
    "                if R[i][j] > 0: #if element > 0 (aka if a rating is there):\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i,:],Q[:,j]), 2) #sum up the square of the error\n",
    "                    for k in xrange(K): \n",
    "                        #for each element in R matrx, iterate K also\n",
    "                            e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2) )\n",
    "        print '=============== Step %s =============' % step\n",
    "        print np.dot(P,Q)\n",
    "        print 'Total squared error for step %s' %step\n",
    "        print e\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the ground truth matrix\n",
      "[[5 3 4 0 1 3]\n",
      " [5 0 0 1 4 5]\n",
      " [4 1 2 4 5 2]\n",
      " [4 3 4 2 4 5]\n",
      " [2 4 1 1 0 5]\n",
      " [1 1 5 1 1 0]]\n",
      "=============== Step 0 =============\n",
      "[[ 0.92581623  0.91391792  0.85486489  0.83337782  0.62720094  0.43445172]\n",
      " [ 0.1325813   0.32460568  0.17891314  0.13082131  0.27331743  0.13289893]\n",
      " [ 0.91698515  0.93080109  0.85417594  0.82694522  0.64546728  0.43964826]\n",
      " [ 0.58391647  1.48200305  0.80324326  0.57926779  1.25335346  0.60442304]\n",
      " [ 0.61312005  1.23147463  0.74874657  0.58900475  1.0085312   0.5162016 ]\n",
      " [ 0.39797065  1.01399147  0.54859864  0.39503494  0.8579471   0.41337951]]\n",
      "Total squared error for step 0\n",
      "245.993198789\n",
      "=============== Step 1 =============\n",
      "[[ 1.14257885  1.09204038  1.04633081  0.96937728  0.80527588  0.62336351]\n",
      " [ 0.26738426  0.48086411  0.31476665  0.23406391  0.4066785   0.24455602]\n",
      " [ 1.13885757  1.12312104  1.05366996  0.96732883  0.83620245  0.63650338]\n",
      " [ 0.84666381  1.72496194  1.05947299  0.7476322   1.4837001   0.86298939]\n",
      " [ 0.7983519   1.39234262  0.92635535  0.69747484  1.17220409  0.71117755]\n",
      " [ 0.53907993  1.1184181   0.68081933  0.47666935  0.96417219  0.55828495]]\n",
      "Total squared error for step 1\n",
      "220.714214244\n",
      "=============== Step 2 =============\n",
      "[[ 1.39847188  1.28453569  1.26498837  1.1209435   1.01024943  0.85461391]\n",
      " [ 0.44651249  0.66601795  0.48772834  0.35959418  0.57540291  0.40292548]\n",
      " [ 1.39896527  1.32678949  1.27912982  1.12161548  1.05190997  0.87616161]\n",
      " [ 1.1565568   1.98480077  1.34839346  0.93313869  1.74700531  1.17564693]\n",
      " [ 1.01171443  1.56179047  1.12237373  0.81512239  1.35584746  0.93974928]\n",
      " [ 0.69728017  1.22509938  0.82226697  0.56277129  1.08139589  0.72326342]]\n",
      "Total squared error for step 2\n",
      "193.551064703\n",
      "=============== Step 3 =============\n",
      "[[ 1.68873627  1.48353954  1.50447048  1.28386344  1.23669749  1.12402196]\n",
      " [ 0.67311401  0.87702398  0.69789786  0.50687688  0.78023721  0.61244032]\n",
      " [ 1.69082504  1.53278914  1.52263364  1.28464508  1.28590765  1.1526987 ]\n",
      " [ 1.50650822  2.25060573  1.66090358  1.12955688  2.03559899  1.53629394]\n",
      " [ 1.24763683  1.73287131  1.33046036  0.93768692  1.55407573  1.19691521]\n",
      " [ 0.86809645  1.32932462  0.96822307  0.65033351  1.20561312  0.90393802]]\n",
      "Total squared error for step 3\n",
      "165.995336527\n",
      "=============== Step 4 =============\n",
      "[[ 2.00325557  1.67902867  1.75478461  1.4517643   1.47562784  1.42180079]\n",
      " [ 0.94528073  1.10745098  0.94118696  0.67277982  1.01806928  0.87242532]\n",
      " [ 2.00253656  1.73024713  1.77276003  1.44922615  1.52800411  1.45442508]\n",
      " [ 1.88254344  2.50895973  1.98333826  1.32804142  2.33730679  1.93147847]\n",
      " [ 1.49656196  1.89749995  1.54184945  1.05952787  1.75900988  1.47341412]\n",
      " [ 1.04474661  1.42607768  1.11278052  0.73570572  1.33152151  1.09344644]]\n",
      "Total squared error for step 4\n",
      "139.770015631\n",
      "=============== Step 5 =============\n",
      "[[ 2.32739148  1.86038578  2.00361952  1.6169109   1.71545869  1.73337965]\n",
      " [ 1.25514401  1.34803184  1.20927316  0.85157741  1.28161444  1.17608417]\n",
      " [ 2.31811791  1.90832067  2.01630458  1.60719146  1.76585599  1.76521114]\n",
      " [ 2.26536373  2.74627676  2.29955536  1.51843465  2.63707106  2.3419265 ]\n",
      " [ 1.74610899  2.04788987  1.74673406  1.1744662   1.96136924  1.75689902]\n",
      " [ 1.21909522  1.51096888  1.2498456   0.8151807   1.45332667  1.28344479]]\n",
      "Total squared error for step 5\n",
      "116.429377077\n",
      "=============== Step 6 =============\n",
      "[[ 2.64441337  2.01843248  2.23856732  1.77155044  1.94396524  2.04181892]\n",
      " [ 1.58956295  1.58813511  1.49075228  1.03567798  1.56023347  1.51108109]\n",
      " [ 2.62040545  2.0583928   2.2408123   1.75092595  1.9872233   2.06740007]\n",
      " [ 2.63386393  2.95153637  2.59405791  1.69115657  2.9196994   2.74607098]\n",
      " [ 1.98328147  2.17808606  1.93611566  1.2768886   2.15211591  2.0341641 ]\n",
      " [ 1.38312936  1.58108865  1.37428308  0.88565637  1.56577064  1.46562329]]\n",
      "Total squared error for step 6\n",
      "96.9879228064\n",
      "=============== Step 7 =============\n",
      "[[ 2.93879213  2.14717116  2.44949304  1.90936071  2.15056508  2.33105987]\n",
      " [ 1.93242844  1.8177045   1.77320517  1.21691554  1.84174585  1.86171672]\n",
      " [ 2.89453529  2.17570708  2.43698249  1.87481651  2.1823213   2.34529083]\n",
      " [ 2.96941053  3.11834098  2.85498745  1.83900325  3.17276163  3.12433931]\n",
      " [ 2.19695935  2.28499107  2.10342864  1.36271948  2.32406418  2.29362788]\n",
      " [ 1.53043908  1.63544837  1.48277888  0.94513812  1.66501511  1.63318622]]\n",
      "Total squared error for step 7\n",
      "81.7538019316\n",
      "=============== Step 8 =============\n",
      "[[ 3.19907831  2.2445596   2.63014643  2.02646334  2.32807977  2.58876807]\n",
      " [ 2.26776526  2.02894028  2.04541626  1.38795696  2.11459639  2.21190566]\n",
      " [ 3.13061216  2.25980369  2.60001183  1.97607386  2.3453595   2.58782312]\n",
      " [ 3.25918269  3.24551511  3.07584261  1.95818471  3.38852869  3.46252288]\n",
      " [ 2.3797194   2.36852025  2.24534801  1.42992017  2.47286912  2.52714032]\n",
      " [ 1.65715696  1.67487009  1.57412967  0.99291869  1.74907644  1.7817711 ]]\n",
      "Total squared error for step 8\n",
      "70.4187894529\n",
      "=============== Step 9 =============\n",
      "[[ 3.41932329  2.31214682  2.77852744  2.12169097  2.47339759  2.80780145]\n",
      " [ 2.58244051  2.21716077  2.29895795  1.54334013  2.36959697  2.54783869]\n",
      " [ 3.32464548  2.31375429  2.72953211  2.05471184  2.47481193  2.7895994 ]\n",
      " [ 3.4974459   3.33624051  3.25549798  2.04834396  3.56439504  3.75316041]\n",
      " [ 2.52842089  2.43097066  2.36163587  1.47842207  2.59715382  2.73060589]\n",
      " [ 1.76210782  1.70145462  1.64896347  1.02943151  1.81774371  1.90960315]]\n",
      "Total squared error for step 9\n",
      "62.3088073362\n",
      "=============== Step 0 =============\n",
      "[[ 3.59883308  2.35393831  2.89615714  2.19617087  2.58704049  2.98611555]\n",
      " [ 2.86763994  2.38074155  2.52877104  1.6798895   2.60077342  2.85954647]\n",
      " [ 3.4777952   2.34273578  2.82849742  2.11287822  2.57261258  2.95029653]\n",
      " [ 3.68477788  3.39637435  3.39693915  2.11178702  3.70200057  3.99496959]\n",
      " [ 2.64364505  2.47600898  2.45432551  1.50965255  2.69794737  2.90353253]\n",
      " [ 1.84630646  1.71790534  1.7091304   1.05590391  1.87213695  2.01704432]]\n",
      "Total squared error for step 0\n",
      "56.6462075906\n",
      "=============== Step 1 =============\n",
      "[[ 3.74080185  2.37507069  2.98680597  2.25254151  2.67207817  3.12559912]\n",
      " [ 3.11899412  2.52042821  2.73287111  1.79655945  2.80531991  3.14122583]\n",
      " [ 3.59467293  2.35259537  2.90169885  2.15393413  2.64284946  3.0731579 ]\n",
      " [ 3.82611376  3.43273056  3.50551811  2.15239395  3.80572187  4.19113159]\n",
      " [ 2.72851047  2.50770549  2.52670395  1.52591496  2.77781557  3.04799263]\n",
      " [ 1.91215488  1.72695237  1.7570499   1.07396881  1.91414609  2.10586912]]\n",
      "Total squared error for step 1\n",
      "52.7270681858\n",
      "=============== Step 2 =============\n",
      "[[ 3.85061222  2.38073636  3.05523123  2.29414138  2.73291608  3.23054618]\n",
      " [ 3.33578197  2.63843937  2.911578    1.89393802  2.98297933  3.39067732]\n",
      " [ 3.68153624  2.34881511  2.95446558  2.18162445  2.69050386  3.16333388]\n",
      " [ 3.92860456  3.45181735  3.58739747  2.17461872  3.88117905  4.34733803]\n",
      " [ 2.78742065  2.52985714  2.5824434   1.52983367  2.84002592  3.16749546]\n",
      " [ 1.96266636  1.73099018  1.79520211  1.08534594  1.94593866  2.17855923]]\n",
      "Total squared error for step 2\n",
      "49.9971052455\n",
      "=============== Step 3 =============\n",
      "[[ 3.93438016  2.37552635  3.10623775  2.32437957  2.77430899  3.30629379]\n",
      " [ 3.5197782   2.73766878  3.06665276  1.9736582   3.13522335  3.60834373]\n",
      " [ 3.74489302  2.33596892  2.99180212  2.19950536  2.72053118  3.22655187]\n",
      " [ 3.99991973  3.45915148  3.6484916   2.18278152  3.93411889  4.47018528]\n",
      " [ 2.82508228  2.54563933  2.62502667  1.52396369  2.88792839  3.26607463]\n",
      " [ 2.00089323  1.7319227   1.82582057  1.09163417  1.96961979  2.23777102]]\n",
      "Total squared error for step 3\n",
      "48.0569818555\n",
      "=============== Step 4 =============\n",
      "[[ 3.99797883  2.36315218  3.14412913  2.34634835  2.80072259  3.35825809]\n",
      " [ 3.67416295  2.82112015  3.20057344  2.03788033  3.26449545  3.79633074]\n",
      " [ 3.79065863  2.31756821  3.01795672  2.21064028  2.73733611  3.26826589]\n",
      " [ 4.04718681  3.45903624  3.69391248  2.18067587  3.96975174  4.56611433]\n",
      " [ 2.84589156  2.55750966  2.65745451  1.51057133  2.92458521  3.34768528]\n",
      " [ 2.02959165  1.73115307  1.85075814  1.09420663  1.98704597  2.2860065 ]]\n",
      "Total squared error for step 4\n",
      "46.6348777821\n",
      "=============== Step 5 =============\n",
      "[[ 4.04652356  2.34642284  3.17247614  2.36264382  2.81601062  3.39137729]\n",
      " [ 3.80268937  2.89157783  3.31602823  2.08891295  3.37363573  3.95760901]\n",
      " [ 3.82377932  2.29613812  3.0362998   2.217498    2.74456063  3.29322778]\n",
      " [ 4.0764849   3.45462153  3.72778684  2.17141904  3.99245843  4.64084622]\n",
      " [ 2.85363688  2.56725946  2.682155    1.49154674  2.95260218  3.41587779]\n",
      " [ 2.05107676  1.72964948  1.87146741  1.09417958  1.99975428  2.32545136]]\n",
      "Total squared error for step 5\n",
      "45.5519453107\n",
      "=============== Step 6 =============\n",
      "[[ 4.0841916   2.32735451  3.19408858  2.3753279   2.82331479  3.40986607]\n",
      " [ 3.90914017  2.95145686  3.41561028  2.12897339  3.46550315  4.09545173]\n",
      " [ 3.84816205  2.27339368  3.04937872  2.22197244  2.74506943  3.30534909]\n",
      " [ 4.09271306  3.44809242  3.75329131  2.15745384  4.00573837  4.69916943]\n",
      " [ 2.85141638  2.5761293   2.70100964  1.46839951  2.97409214  3.47366779]\n",
      " [ 2.06720051  1.7280373   1.88904174  1.09242448  2.00896278  2.35792508]]\n",
      "Total squared error for step 6\n",
      "44.692500087\n",
      "=============== Step 7 =============\n",
      "[[ 4.11424081  2.30732756  3.21109292  2.38596889  2.82509447  3.41716794]\n",
      " [ 3.99702258  3.00276689  3.50166333  2.16005961  3.54275995  4.21308332]\n",
      " [ 3.86676728  2.25043454  3.05904909  2.22546019  2.74103591  3.30772954]\n",
      " [ 4.0996665   3.44088854  3.77278809  2.14062679  4.01228646  4.74493655]\n",
      " [ 2.8416763   2.58493669  2.71543238  1.4422976   2.99071077  3.52352472]\n",
      " [ 2.07939432  1.72668937  1.90427941  1.08960068  2.01560653  2.3848944 ]]\n",
      "Total squared error for step 7\n",
      "43.9820724699\n",
      "=============== Step 8 =============\n",
      "[[ 4.13912414  2.28724253  3.2250502   2.39571617  2.82321716  3.41601377]\n",
      " [ 4.06942967  3.04713714  3.57622452  2.18389829  3.6077704   4.31348651]\n",
      " [ 3.88176652  2.22791833  3.06662281  2.22895549  2.73406471  3.30276248]\n",
      " [ 4.10020259  3.4339047   3.78798867  2.12229334  4.01412237  4.7811643 ]\n",
      " [ 2.82630324  2.59419055  2.72646275  1.41412307  3.00372331  3.5674208 ]\n",
      " [ 2.08873754  1.72580202  1.91774983  1.08619403  2.02038649  2.40751664]]\n",
      "Total squared error for step 8\n",
      "43.3725578767\n",
      "=============== Step 9 =============\n",
      "[[ 4.16063525  2.26765372  3.2370772   2.40538221  2.81906705  3.40852529]\n",
      " [ 4.12900451  3.08586792  3.6410231   2.2019395   3.66257134  4.39931566]\n",
      " [ 3.89470886  2.20619935  3.07300311  2.23314091  2.72531517  3.29226357]\n",
      " [ 4.09642718  3.42765429  3.80010818  2.10342274  4.01272799  4.8101708 ]\n",
      " [ 2.80673037  2.60418345  2.73485325  1.38452944  3.01407813  3.60690361]\n",
      " [ 2.09602931  1.72545392  1.92985181  1.08255393  2.02381848  2.42669211]]\n",
      "Total squared error for step 9\n",
      "42.8326295628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.83403387,  0.41781682],\n",
       "        [ 1.56070215,  1.27055253],\n",
       "        [ 1.69089255,  0.47663879],\n",
       "        [ 1.43471259,  1.63562729],\n",
       "        [ 0.90363501,  1.38260931],\n",
       "        [ 0.74291519,  0.80782788]]), array([[ 2.12206343,  0.64310253],\n",
       "        [ 0.94857244,  1.2635675 ],\n",
       "        [ 1.54431835,  0.96871409],\n",
       "        [ 1.27292475,  0.16944054],\n",
       "        [ 1.22247141,  1.38101932],\n",
       "        [ 1.48532861,  1.63799612]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "test_R = np.random.randint(0,6, (6,6))\n",
    "test_P, test_Q = initialize_random_matrices(test_R, 2)\n",
    "print 'This is the ground truth matrix'\n",
    "print test_R\n",
    "\n",
    "test_P, test_Q = matrix_factorization_test(test_R, test_P, test_Q, 2, steps=10, alpha=0.005)\n",
    "matrix_factorization_test(test_R, test_P, test_Q, 2, steps=10, alpha=0.005)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_P_df = pd.DataFrame(test_P)\n",
    "test_P_df.to_pickle('test_P.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_factorization(R, P, Q, K, steps=1000, alpha=0.0002, beta=0.02):\n",
    "    Q = Q.T\n",
    "    for step in xrange(steps):\n",
    "        for i in xrange(len(R)): # iterate over rows (or users)\n",
    "            for j in xrange(len(R[i])): # for each user, iterate all items. 30 times.\n",
    "                #Hence, iterate over entire row of matrix R, before moving on to next row.\n",
    "                if R[i][j] > 0: # If a given element in a matrix is > 0, aka user has actually rated an item\n",
    "                    # eij is the error for a given element in matrix R\n",
    "                    eij = R[i][j] - np.dot(P[i,:],Q[:,j]) \n",
    "                    # Iterate over the user:feature matrix.\n",
    "                    for k in xrange(K): # K is number of latent features. \n",
    "                        # Updating each indivudual feature of the matrix P and matrix Q. \n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eR = np.dot(P,Q)\n",
    "        e = 0\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])): #for elements in the original matrix:\n",
    "                if R[i][j] > 0: #if element > 0 (aka if a rating is there):\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i,:],Q[:,j]), 2) #sum up the square of the error\n",
    "                    for k in xrange(K): \n",
    "                        #for each element in R matrx, iterate K also\n",
    "                            e = e + (beta/2) * ( pow(P[i][k],2) + pow(Q[k][j],2) )\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation and Findings\n",
    "\n",
    "\n",
    "1. With 20 latent factors, steps=500, alpha=0.002. Rmse is 1.0118604462. Runtime 120 minutes. \n",
    "\n",
    "2. With 40 latent factors, steps=500, alpha=0.002. Rmse is 1.11010187762. Runtime 192 minutes.\n",
    "\n",
    "3. First de-meaning the data, then running experiment 1.\n",
    "\n",
    "Huge improvement from cosine similarity and SVD! (In RMSE, not runtime.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing train/test matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "train, test = train_test_split(ratings_df, 0.7)\n",
    "\n",
    "train_matrix = train.pivot(index='UserID', columns = 'MovieID', values='Rating')\n",
    "test_matrix = test.pivot(index='UserID', columns = \"MovieID\", values='Rating')\n",
    "train_matrix.drop(999, inplace=True)\n",
    "test_matrix.drop(999, inplace=True)\n",
    "test_matrix.fillna(0,inplace=True)\n",
    "train_matrix.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "train_matrix = np.array(train_matrix)\n",
    "test_matrix = np.array(test_matrix)\n",
    "\n",
    "ground_truth = ratings_df.pivot(index='UserID', columns='MovieID', values='Rating')\n",
    "\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671, 20)\n",
      "(9066, 20)\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "P, Q = initialize_random_matrices(train_matrix, 20)\n",
    "\n",
    "print P.shape\n",
    "print Q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Load the pickled result, or run the cell (running the cell will take about 120 minutes)</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_P = pd.read_pickle('result_P_df.pkl')\n",
    "result_P = np.array(result_P)\n",
    "\n",
    "result_Q = pd.read_pickle('result_q_df.pkl')\n",
    "result_Q = np.array(result_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9301.90666658\n"
     ]
    }
   ],
   "source": [
    "# This cells takes a 2 hours to run.\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "\n",
    "result_P, result_Q = matrix_factorization(train_matrix, P, Q, 20, steps=500)\n",
    "\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### <span style=\"color:red\">This cell is to create pickle of P and Q matrices. Do not need to run.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_P_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-abaf832b8aa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresult_Q_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_Q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult_P_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result_P_df.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mresult_Q_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result_q_df.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result_P_df' is not defined"
     ]
    }
   ],
   "source": [
    "result_P_df = pd.DataFrame(result_P)\n",
    "result_Q_df = pd.DataFrame(result_Q)\n",
    "\n",
    "result_P_df.to_pickle('result_P_df.pkl')\n",
    "result_Q_df.to_pickle('result_q_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18185038,  0.81896762,  0.42939372, ..., -0.0979881 ,\n",
       "         0.4433499 , -0.33576179],\n",
       "       [ 0.75219213,  0.49994733,  0.16029375, ..., -0.15039515,\n",
       "         0.69359448,  0.61478643],\n",
       "       [ 0.46303588, -0.34371818,  0.28892853, ...,  0.59892686,\n",
       "        -0.1375437 ,  0.49941571],\n",
       "       ..., \n",
       "       [ 0.17701386,  0.36887833,  0.63718673, ...,  0.06686219,\n",
       "         0.512445  ,  0.37392249],\n",
       "       [ 0.60310777,  0.45863913,  0.35570067, ..., -0.3366204 ,\n",
       "         0.05125785,  0.82396467],\n",
       "       [ 0.31844834,  0.81056969,  0.43695203, ...,  0.26658399,\n",
       "         0.29761829,  0.83935853]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting results by multipling P and Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671, 20)\n",
      "(9066, 20)\n",
      "(20, 9066)\n"
     ]
    }
   ],
   "source": [
    "print result_P.shape\n",
    "print result_Q.shape\n",
    "result_Q = result_Q.T\n",
    "print result_Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = np.dot(result_P, result_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(result).to_pickle('results_GD.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_df.to_pickle('mvies_df.pkl')\n",
    "ratings_df.to_pickle('ratings_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the RMSE of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rmse is 1.0118604462 \n"
     ]
    }
   ],
   "source": [
    "ground_truth_list = []\n",
    "result_list = []\n",
    "\n",
    "ground_truth_array = np.array(ground_truth)\n",
    "result_array = np.array(result)\n",
    "\n",
    "i, j = np.where(test_matrix != 0)\n",
    "locators = zip(i,j)\n",
    "\n",
    "for i in locators:\n",
    "    ground_truth_list.append(ground_truth_array[i])\n",
    "    result_list.append(result_array[i])\n",
    "\n",
    "ground_truth_array = np.array(ground_truth_list)\n",
    "result_array = np.array(result_list)\n",
    "\n",
    "rmse = np.sqrt(sum((ground_truth_array - result_array) ** 2) / len(ground_truth_array))\n",
    "\n",
    "print 'Rmse is %s ' % rmse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                              \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2:  40 latent factors\n",
    "\n",
    "<span style=\"color:blue\">This cell takes about 180 minutes to run.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P_40, Q_40 = initialize_random_matrices(train_matrix, 40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671, 40)\n",
      "(9066, 40)\n"
     ]
    }
   ],
   "source": [
    "print P_40.shape\n",
    "print Q_40.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11575.6989019\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "\n",
    "result_P_40, result_Q_40 = matrix_factorization(train_matrix, P_40, Q_40, 40, steps=500)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print elapsed\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.28080323,  2.75795705,  2.26646699, ...,  2.40537265,\n",
       "         2.97339885,  3.22176373],\n",
       "       [ 3.72343195,  3.08853744,  2.78249104, ...,  3.87448963,\n",
       "         4.34606285,  3.85102228],\n",
       "       [ 4.62208284,  2.91481741,  4.20128246, ...,  4.61615354,\n",
       "         3.88740339,  3.46705855],\n",
       "       ..., \n",
       "       [ 3.81787055,  3.83193719,  3.49064371, ...,  3.16196186,\n",
       "         3.09550821,  4.76899905],\n",
       "       [ 4.13851594,  3.52177309,  3.50858171, ...,  4.6557265 ,\n",
       "         3.58306072,  3.02560616],\n",
       "       [ 4.84760756,  3.98397751,  3.11935125, ...,  3.29496466,\n",
       "         3.75185728,  3.36249914]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_40 = np.dot(result_P_40, result_Q_40.T)\n",
    "result_40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rmse is 1.11010187762 \n"
     ]
    }
   ],
   "source": [
    "ground_truth_list = []\n",
    "result_list = []\n",
    "\n",
    "ground_truth_array = np.array(ground_truth)\n",
    "result_array = np.array(result_40)\n",
    "\n",
    "i, j = np.where(test_matrix != 0)\n",
    "locators = zip(i,j)\n",
    "\n",
    "for i in locators:\n",
    "    ground_truth_list.append(ground_truth_array[i])\n",
    "    result_list.append(result_array[i])\n",
    "\n",
    "ground_truth_array = np.array(ground_truth_list)\n",
    "result_array = np.array(result_list)\n",
    "\n",
    "rmse = np.sqrt(sum((ground_truth_array - result_array) ** 2) / len(ground_truth_array))\n",
    "\n",
    "print 'Rmse is %s ' % rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
